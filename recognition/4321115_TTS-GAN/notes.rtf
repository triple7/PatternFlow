{\rtf1\ansi\ansicpg1252\cocoartf2576
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \CocoaLigature0 Generative adversarial networks have seen rapid development in recent years and have led to remarkable improvements in generative modelling of images. How- ever, their application in the audio domain has received limited attention, and autoregressive models, such as WaveNet, remain the state of the art in genera- tive modelling of audio signals such as human speech. To address this paucity, we introduce GAN-TTS, a Generative Adversarial Network for Text-to-Speech. Our architecture is composed of a conditional feed-forward generator producing raw speech audio, and an ensemble of discriminators which operate on ran- dom windows of different sizes. The discriminators analyse the audio both in terms of general realism, as well as how well the audio corresponds to the utterance that should be pronounced. To measure the performance of GAN-TTS, we employ both subjective human evaluation (MOS \'96 Mean Opinion Score), as well as novel quantitative metrics (Fre\uc0\u32 \u769 chet DeepSpeech Distance and Kernel DeepSpeech Distance), which we find to be well correlated with MOS. We show that GAN-TTS is capable of generating high-fidelity speech with natural- ness comparable to the state-of-the-art models, and unlike autoregressive models, it is highly parallelisable thanks to an efficient feed-forward generator. Listen to GAN-TTS reading this abstract  at https://storage.googleapis.c om/ deepmind-media/research/abstract. wav .
\f1\fs24 \cf0 \CocoaLigature1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
GANTTS\
\
generator:\
input - sequence of human speech with linguistic features, encoded phonetics, pitch, duration (logarithmic fundamental frequency at 200 hz)\
7 g blocks with 2 skip layers:\
1- upsampling when the frequency is higher than the input\
2-size 1 convolution when the when number of output channels does not match the input channels\
\
random window discriminators:\
Each discriminator has d blocks:\
conditional batch normalisation:\
https://paperswithcode.com/method/conditional-batch-normalization\
\
}